# Learning Outcome 3: Assess the general quality of the raw data from the sequencing facility

## LO 3.1 - Interpret what are fastq files and what is their content

Most high-throughput sequencing (HTS) machines output [fastq files](https://en.wikipedia.org/wiki/FASTQ_format), the “de facto” current standard in HTS. Fastq files are simply text files, where each block of information (a sequenced DNA fragment, or read) in this format is encoded as 4 lines:

	@read_identifier
	read_sequence
	+ separator line
	base_qualities

Each base has a quality character associated with it, which represents how confidently the
machine identified (called) the base. The probability of error per base is given as a [Phred score](https://en.wikipedia.org/wiki/Phred_quality_score), calculated from an integer value (Q) derived from the quality character associated to the base. Useful reference values of Q include:
* Q=10 - 90% accuracy
* Q=20 - 99% accuracy
* Q=30 - 99.9% accuracy
* Q=40 - 99.99% accuracy

Although there's theoretically no limit, Q usually goes up to around 40 in recent illumina machines.

You can see a few fastq files in the folder fastq_examples:
* sample_quality_and_adaptors.fastq.gz
* sample_adaptors.fastq.gz
* 20150821.A-2_BGVR_P218_R1.sample.fastq.gz
* 20150821.A-2_BGVR_P218_R2.sample.fastq.gz

Since each fastq can have several million reads, they can become very big. Therefore, it is usual to keep them in a compressed format such as gzip. Most recent software can directly read compressed fastq files.

**Task**: Upload all the sample files into your Galaxy and inspect them

You probably noticed that two of the example files have the same name, except for R1 and R2. This is an example of a paired-end dataset. If you inspect both datasets, you can find the same identifiers in each of the files, in the same order. In R1 you have forward reading of a fragment, and in R2 you have the reverse reading of the same fragment. Depending on the length of the fragment, they may or may not contain overlapping sequences. 


## LO 3.2 - Use software like FastQC to process fastq files and produce QC reports

High Throughput Sequencing machines read thousands or millions of sequences in paralell. As you can imagine, this usually generates large fastq files, with millions of lines, and thus manually inspecting the quality of each read is out of the question. Specialized software has been developed to provide quality measures for fastq files generated by HTS machines. [FastQC](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/) is a popular program to generate quality reports on fastq data. Running FastQC on your raw data is usually the first thing you should do once you receive a new dataset.

**Task**: Run FastQC in each of the example files


## LO 3.3 - Read QC reports of raw data to assess the general quality of data and presence of sequence bias

**Task**: Inspect the FastQC Reports generated previously

Detect low quality bases in the QC reports

Detect sequence bias and possible presence of adaptors and other contaminants

The FastQC reports provide a series of plots that allow the user to assess the overall quality of their raw data and detect potential biases and problems. 

One of the plots indicates the distribution of base qualities (as Q values representing the confidence in the base) along the length of the reads. You can notice that, at least for illumina data, on average the quality of each base tends to decrease along the length of the read. The beginning of the read may also be problematic. You can also see that the reverse read (R2) is usually of worse quality than the forward read (R1). Therefore, short single-end reads usually have better average quality, and are often ready to use right out of the sequencer.

[images of quality]

Other plots indicate biases in the nucleotidic content of the reads, either globally (as the %GC plots), or positionally. Global bias in nucleotidic content can be useful to search for signs of contaminants. On the other hand, positional bias are useful to detect the presence of artefactual sequences in your reads such as the adaptors that are necessary to add to the fragments so that the machine can actually read them. Another insight you may obtain from this information are potential biases in the preparation of your library. For example, random hexamer priming is actually not truly random, and preferentially selects certain sequences. The currently popular transposase-based enzymatic protocol, although reasonably random, is also not completely random, and you can see this through positional bias, particularly in the beginning of reads.

[images of positional bias, including positional biases of Nextera]


# Learning Outcome 4: Do simple processing operations in the raw data to improve its quality

## LO 4.1 - Use tools such as seqtk and trimmomatic to remove low quality bases from your reads

In most cases, particularly if you're sequencing short, single-end reads, the quality of your raw data is good enough to continue without any preprocessing. In fact, if you send your sequencing to an external facility, they often do these verifications and filtering for you, and you have “clean” sequences in the end, but it is always better to check. 

Nonetheless, sometimes things can go wrong, and you may need to do something about it. As you may have noticed before, reads tend to lose quality towards their end, where there is a higher probability of erroneous bases being called. To avoid problems in subsequent analysis, you should remove regions of poor quality in your read, usually by trimming them from the end of reads using tools such as [seqtk](https://github.com/lh3/seqtk). 

QUESTION: Even if all bases that your machine reads have a Q=20 (1% error rate), what is the probability that one 100bp read is completely correct? To answer this, consider also that all bases are read independently.

TASK: Use seqtk_trimfq with different error thresholds in the example datasets. Use FastQC to evaluate the impact of the procedure.

QUESTION: If you are too stringent, you may remove too many bases, but if you are too lenient, you may fall in local optima, because behind a good quality base may be more bad quality ones. What other strategies you can imagine to filter your reads?

Another popular tool to filter fastq files is [Trimmomatic](http://www.usadellab.org/cms/?page=trimmomatic). This tool implements more ellaborate trimming strategies, such as average window threshold.

Task: Use Trimmomatic to remove low quality bases from the example datasets. Notice that the default method in Trimmomatic is a 4bp window average, with a threshold of Q=20. Finally, look at the impact using FastQC of trimmed reads. NOTE: Trimmomatic requires you to specify that you use the "standard" Phred Q scale (fastqsanger), which was different from the one used in older datasets (before 2012), so you need to manually change the datatype of your dataset from generic fastq to fastqsanger.

## LO 4.2 - Use tools such as cutadapt to remove adaptors and other artefactual sequences from your reads

Sequence machines often require that you add specific sequences (adaptors) to your DNA so that it can be sequenced. For many different reasons, such sequences may end up in your read, and you usually want to remove these adaptors. To remove them, not only you have to look for the sequence in the reads, but also allow for sequencing errors, as well as the presence of incomplete sequences. Tools such as [cutadapt](http://cutadapt.readthedocs.io/en/stable/guide.html) do precisely this.

TASK: Use cutadapt to remove adaptors from sample_adaptors.fastq. In this sample, we know that we used the illumina adaptor AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC, so try to remove this from the 3' end of reads and see the impact of the procedure. What happened? You noticed that almost no read was affected. This is because what you get in reads is a readthrough, so what you are actually reading in the ends of reads is the reverse complement of the adaptor. Now, try the same procedure but with GTGACTGGAGTTCAGACGTGTGCTCTTCCGATCT (reverse complement of the previous). Much better, no? 

Another frequent "artefactual" sequence (in the sense that is non-genomic) present in RNA-Seq reads, particularly in datasets coming from TruSeq library preparation protocols (not so much with protocols like SMART-Seq that use Nextera), is poly-A tails. You can also remove them relatively easily using cutadapt with AAAAAAAAAA(...) or/and TTTTTTTTTT(...) as adaptors.

One issue of removing the adaptors is that you need to know which ones were used in your data. FastQC already can already give you which one was used, and you can then go to the illumina manual to search for its sequence. But since Illumina is used most of the time, these adaptors are already integrated in some tools like Trimmomatic, which also take in consideration issues like reverse complement. 

TASK: Use Trimmomatic to remove adaptors from sample_adaptors.fastq using Truseq adaptors.

Overall, you can use Trimmommatic to do both quality and adaptor trimming. Moreover, Trimmomatic includes widely used adaptors and also transparently handles the issue of paired-end, in case you have this. So it's probably a good choice for general use.

Task: Use Trimmommatic to do quality filtering and adaptor trimming in sample_quality_and_adaptors.fastq (use Nextera adaptors), as well as in the paired-end example RNA-Seq data (use Truseq adaptors). Use FastQC to evaluate the impact of the procedure. Notice that, if you're too strict, you may end up loosing valuable data.

Task: Use Trimmomatic or any of the other tools we tried so far in your own data, if necessary. Usually, particularly if you used small  single-end reads, your data should be ready to use from the start and you don't need to do anything.

# Learning Outcome 5: Generate alignments of processed reads against a reference genome

## LO 5.1 - What is a reference genome, versioning and where to obtain genomes

Now that you've checked the quality of your raw data, and did any necessary preprocessing, you should now be ready to use it. 

To check which genes are expressing, you need to align your reads against a reference genome. These were (and are still) usually obtained through the efforts of large consortia, which eventually create portals that make the data available for the scientific community. [ENSEMBL](http://www.ensembl.org) (in Europe) and [UCSC genome browser](http://genome.ucsc.edu/) (in the US) emerged first as resources to display and explore the human data, and latter agglomerated data for other model and non-model organisms, making them very convenient resources for high quality genomes. 


Another alternative is to use cDNA sequences directly as a reference. 



Task: Obtain genomic fasta for Drosophila melanogaster from the Ensembl website. Finally, also download a fasta with cDNA. 


Task: Obtain genomic and cDNA fasta from you species of interest from ENSEMBL. If you're using a non-vertebrate species, you may need to go to other Ensembl sites, such as Ensembl bacteria, protists, metazoa, or plants. Take note of the Ensembl version, as well as the version of your genome (in case later you wanto to integrate data that is not from Ensembl). 

## LO 5.2 - Alignment software: tophat2/hisat2; bwa; sailfish/salmon

To be able to align millions of short reads to a (sometimes large) reference genome, novel, more efficient, alignment methods had to be developed. One popular method is based on the [burrows-wheeler transform](https://en.wikipedia.org/wiki/Burrows%E2%80%93Wheeler_transform) and the use of efficient data structures, of which [bwa](http://bio-bwa.sourceforge.net/) and [bowtie](http://bowtie-bio.sourceforge.net/index.shtml) are examples. They enable alignment of millions of reads in a few minutes, even in a common laptop. 

Methods such as the ones based on the burrows-wheeler transform make some assumptions to speed up the alignment process. Namely, they require the reference genome to be very similar to your sequenced DNA (less than 2-5% differences). For example, you probably cannot align mouse data to the human genome, although in the case of RNA-Seq this is less problematic since genes tend to be much better conserved than the rest of the genome (you would probably still bias your results to better conserved genes). Moreover, they are not optimal, and therefore sometimes make some mistakes, although they work quite well most of the time. 

RNA-Seq, in eukaryotes contain the extra complication of splicing, whereas. 
When using small, single-end reads, 

Sailfish/Salmon are another set of more recent approaches that are quickly gaining in popularity.


	Question: what are the conditions of using burrows-wheeler approaches?	
	Prepare a reference genome to use with hisat2 and bwa

## LO 5.3 - Run an alignment: the SAM/BAM alignment format


Run hisat2 / bwa mem in an example dataset

To store millions of alignments, researchers also had to develop new, more practical formats. The Sequence Alignment/Map (SAM) format 11 is a tabular text file format, where each line contains information for one alignment. SAM files are most often compressed as BAM (Binary sAM) files, to reduce space and allow direct access to alignments in any arbitrary region of the genome. Several tools only work with BAM files.


			Question: what is the SAM format; what is the BAM format?

		Also briefly look at SAMv1.pdf describing the format to understand the information in the sam files.

	
# Learning Outcome 6: Assess the general quality of the alignments and detect possible problems

		LO 6.1 - Visualizing alignments in IGV for single genes

After finishing your analysis, even if you did all the quality checks, and obtained a list of variants, you
may want to manually inspect your alignments (you should always manually inspect the regions that
are most important for your analysis). For this, there is simple desktop software that you can use to
visualize your data, such as IGV 17 or Tablet 18 .
TASK: Run IGV and look at sample BAM files with alignments
First you'll need a reference genome:

Inspect the pairing information (need to set option on IGV to look at it)

NOTE: next to .bam files there is a .bai file with the same name. The .bai file is called the BAM index
file and it is used to enable tools such as IGV to navigate the alignments much faster (imagine if you
needed to go through millions of alignments every time you moved around in the genome).

[Note that you need to download the .bai file, as well as the bam]

[Check if you can visualize with Galaxy - either directly, or see IGV link??]

NOTE: Most genomes (particularly mamallian genomes) contain areas of low complexity, composed
mostly of repetitive sequences. In the case of short reads, sometimes these align to multiple regions in
the genome equally well, making it impossible to know where the fragment came from. Longer reads
are needed to overcome these difficulties, or in the absence of these, paired-end data can also be used.
Some aligners (such as bwa) can use information on paired reads to help disambiguate some
alignments. Information on paired reads is also added to the SAM file when proper aligners are used.


The data processing is similar to genomic resequencing. For eukaryotes, mRNA is usually spliced, and
thus we need to use splice-aware aligners (eg. Tophat 24 ) to map short reads to a reference genome.
TASK: Look at a RNA-Seq sample in IGV:
- In IGV, load the Drosophila genome as reference; load gtf file annotation and alignment files (*.bam)
- Look at position: 3L:15033260-15038204 (may need to change scale)
- Look at position: X:20564838-20570348 (may need to change scale to 800 to see)
- Look at position X:5793758-5799858 (compare coverage with previous examples)
Notice the 3' bias, particularly in one of the replicates 

[Show the graphs of RSeqQC and Qualimap with the real data? - bring BAM files, do NOT put the whole thing in git]

Would you be able to detect all of what you saw here using microarrays?


NOTE: Similarly to microarrays, RNA-Seq can be used to detect differential expression. Nonetheless,
RNA sequencing suffer from multiple still poorly understood biases, and the methods to deal with them
are not as mature as the methods handling microarrays. Moreover, to obtain better signal-to-noise you
need more sequencing which makes it more expensive. Thus, for “simple” experiments, in organisms
with good quality microarrays available, these may still be more cost-effective and easier to use.
Usually, to perform differential expression analysis, one needs to count how many times a different
transcript/gene is read. A popular tool to generate these counts from a SAM/BAM file is htseq-count 25 .
TASK: Open example_RNA_counts.htseq.tab in the text editor or in a spreadsheet
How would you about checking which genes are differential expressed?
From these count files several methods can be then used to perform statistical tests. Given that
sequencing data is based on discrete counts, most of the popular methods are based on derivations of
the binomial distribution. Similarly to microarrays, there are many available tools to perform these
analysis using the R language (such as edger and DESeq).
TASK: Open example_RNA_counts.edger_analysis.tab and Dmelano_rnaseq.bayseq_diff.txt with a
text editor or in a spreadsheet. How would you go about selecting genes of interest? What would you
do with this list? Is statistically significant the same as biologically significant?
NOTE: Several experiments can have different numbers of reads sequenced (for the same amount of
RNA). Moreover, gene length also influences the number of counts. One common normalization is to
transform counts into FPKM (fragments per kb per million aligned reads). Nonetheless this measure
needs to be used with caution, particularly when comparing different loci.




[Note that you can see variants also with RNA-Seq, if you're interested]


		LO 6.2 - Use tools such as RSeQC and Qualimap to assess quality of alignments
			Interpret general alignment statistics such as percentage of aligned reads
			Check the reports to assess RNA integrity and diversity

After generating alignments and obtaining a SAM/BAM file, how do I know this step went well? The
same way as FastQC generates reports of fastq files to assess quality of raw data, there are programs
that generate global reports on the quality of alignments. One popular tool for this is qualimap 12 .

The way you check if the alignment step went well depends on your application. Usually,
duplication levels higher than 20% are not a good sign (they're a sign of low input DNA and PCR
artifacts) but again, depends on what you are sequencing and how much. Similarly, in the case of
bacterial sequencing or targeted (eg. exonic) sequencing you expect >95% successful alignment, but if
sequencing a full mamallian genome (with many duplicated areas) it may be normal to have as low as
70-80% alignment success. If you have to check the expected “quality” for your application.


Why duplication rates are frequently high in RNA-Seq? 


[lot's of sequence outside annotation, can mean several things: annotation is not correct (eg. if you're working with a non-model organism); DNA contamination (which, if ); immature RNA;]

[Show example plots of some IGC datasets, without showing the actual data!]


# Learning Outcome 7: Generate tables of counts using the alignment and a reference gene annotation

## LO 7.1 - What is a reference gene annotation, versioning and where to obtain
	
		Question: what is the GFF/GTF format?
		Obtain genome GTF from Ensembl

## LO 7.2 - The process of generating gene counts from genome aligments

			Question: what parameters we need to consider when counting?

## LO 7.3 - Use tools such as htseq-counts to generate table of gene counts


# Learning Outcome 8: Generate lists of differentially expressed genes, at least for a simple pairwise comparison

## LO 8.1 - Using the R package edgeR to produce a pairwise differential expression analysis
	
		Use Galaxy to produce differentially expressed genes with edgeR
		Use edgeR in R and RStudio 

## LO 8.2 - Interpretation and visualization of results

		Produce PCA plots comparing all samples: outlier detection
		Visualize expression profiles of top differentially expressed genes
		Produce other plots such as vulcano plots

## LO 8.3 - Use more complex settings: Generalized Linear Models

		Account for confounders using Generalized Linear Models
		Performing ANOVA-like comparisons


# Learning Outcome 9 - Perform simple functional enrichment analysis and understand the concepts behind them

		(TODO: Daniel Faria)
		LO 9.1 - Functional annotations: what are these and where to get them
		LO 9.2 - The statistics behind functional enrichment analysis
		LO 9.3 - Using functional enrichment analysis with your lists of genes






